{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "res = requests.get('https://github.com/topics')\n",
    "res.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Beautiful Soup to Parse and Extract Information\n",
    "- !pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n<!DOCTYPE html>\\n<html\\n  lang=\"en\"\\n  \\n  data-color-mode=\"auto\" data-light-theme=\"light\" data-dark-theme=\"dark\"\\n  data-a11y-animated-images=\"system\" data-a11y-link-underlines=\"true\"\\n  >\\n\\n\\n\\n\\n  <head>\\n    <meta charset=\"utf-8\">\\n  <link rel=\"dns-prefetch\" href=\"https://github.githubassets.com\">\\n  <link rel=\"dns-prefetch\" href=\"https://avatars.githubusercontent.com\">\\n  <link rel=\"dns-prefetch\" href=\"https://github-cloud.s3.amazonaws.com\">\\n  <link rel=\"dns-prefetch\" href=\"https://user-images.githubusercontent.com/\">\\n  <link rel=\"preconnect\" href=\"https://github.githubassets.com\" crossorigin>\\n  <link rel=\"preconnect\" href=\"https://avatars.githubusercontent.com\">\\n\\n  \\n\\n  <link crossorigin=\"anonymous\" media=\"all\" rel=\"stylesheet\" href=\"https://github.githubassets.com/assets/light-0eace2597ca3.css\" /><link crossorigin=\"anonymous\" media=\"all\" rel=\"stylesheet\" href=\"https://github.githubassets.com/assets/dark-a167e256da9c.css\" /><link data-color-theme=\"dark_dimmed\" crossorigin=\"anonymous\" media=\"a'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.text[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "html_doc= BeautifulSoup(res.text, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p>We read every piece of feedback, and take your input very seriously.</p>,\n",
       " <p class=\"text-small color-fg-muted\">\n",
       "             To see all available qualifiers, see our <a class=\"Link--inTextBlock\" href=\"https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax\">documentation</a>.\n",
       "           </p>,\n",
       " <p class=\"f4 color-fg-muted col-md-6 mx-auto\">Browse popular topics on GitHub.</p>,\n",
       " <p class=\"f3 lh-condensed text-center Link--primary mb-0 mt-1\">\n",
       "         Amp\n",
       "       </p>,\n",
       " <p class=\"f5 color-fg-muted text-center mb-0 mt-1\">Amp is a non-blocking concurrency library for PHP.</p>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_tags = html_doc.find_all('p')\n",
    "p_tags[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain Title from github Topics\n",
    "- Use the Inspect option of the broowser to obtain the titles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"f3 lh-condensed mb-0 mt-1 Link--primary\">3D</p>,\n",
       " <p class=\"f3 lh-condensed mb-0 mt-1 Link--primary\">Ajax</p>,\n",
       " <p class=\"f3 lh-condensed mb-0 mt-1 Link--primary\">Algorithm</p>,\n",
       " <p class=\"f3 lh-condensed mb-0 mt-1 Link--primary\">Amp</p>,\n",
       " <p class=\"f3 lh-condensed mb-0 mt-1 Link--primary\">Android</p>,\n",
       " <p class=\"f3 lh-condensed mb-0 mt-1 Link--primary\">Angular</p>,\n",
       " <p class=\"f3 lh-condensed mb-0 mt-1 Link--primary\">Ansible</p>,\n",
       " <p class=\"f3 lh-condensed mb-0 mt-1 Link--primary\">API</p>,\n",
       " <p class=\"f3 lh-condensed mb-0 mt-1 Link--primary\">Arduino</p>,\n",
       " <p class=\"f3 lh-condensed mb-0 mt-1 Link--primary\">ASP.NET</p>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_selected = 'f3 lh-condensed mb-0 mt-1 Link--primary'\n",
    "topic_title_tags = html_doc.find_all('p', {'class' : class_selected})\n",
    "topic_title_tags[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain Description tags\n",
    "- Browser inspect func to get Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_class = 'f5 color-fg-muted mb-0 mt-1'\n",
    "title_desc_tags = html_doc.find_all('p', {'class' : selected_class})\n",
    "title_desc_tags[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain the link to each topics\n",
    "- Get the  link tag to using inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://github.com/topics/3d\n"
     ]
    }
   ],
   "source": [
    "title_desc_tags0 = title_desc_tags[0]\n",
    "link_tag = html_doc.find_all('a', 'no-underline flex-1 d-flex flex-column')\n",
    "topics_url_link = link_tag[0]['href']\n",
    "topics_url = 'https://github.com' +  topics_url_link\n",
    "print(topics_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain each topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3D', 'Ajax', 'Algorithm', 'Amp', 'Android', 'Angular', 'Ansible', 'API', 'Arduino', 'ASP.NET', 'Atom', 'Awesome Lists', 'Amazon Web Services', 'Azure', 'Babel', 'Bash', 'Bitcoin', 'Bootstrap', 'Bot', 'C', 'Chrome', 'Chrome extension', 'Command line interface', 'Clojure', 'Code quality', 'Code review', 'Compiler', 'Continuous integration', 'COVID-19', 'C++']\n"
     ]
    }
   ],
   "source": [
    "topic_title_tags[:5]\n",
    "new_headers = [tags.text for tags in topic_title_tags]\n",
    "print(new_headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain each titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3D refers to the use of three-dimensional graphics, modeling, and animation in various industries.', 'Ajax is a technique for creating interactive web applications.', 'Algorithms are self-contained sequences that carry out a variety of tasks.', 'Amp is a non-blocking concurrency library for PHP.', 'Android is an operating system built by Google designed for mobile devices.', 'Angular is an open source web application platform.', 'Ansible is a simple and powerful automation engine.', 'An API (Application Programming Interface) is a collection of protocols and subroutines for building software.', 'Arduino is an open source platform for building electronic devices.', 'ASP.NET is a web framework for building modern web apps and services.', 'Atom is a open source text editor built with web technologies.', 'An awesome list is a list of awesome things curated by the community.', 'Amazon Web Services provides on-demand cloud computing platforms on a subscription basis.', 'Azure is a cloud computing service created by Microsoft.', 'Babel is a compiler for writing next generation JavaScript, today.', 'Bash is a shell and command language interpreter for the GNU operating system.', 'Bitcoin is a cryptocurrency developed by Satoshi Nakamoto.', 'Bootstrap is an HTML, CSS, and JavaScript framework.', 'A bot is an application that runs automated tasks over the Internet.', 'C is a general purpose programming language that first appeared in 1972.', 'Chrome is a web browser from the tech company Google.', 'Chrome extensions enable users to customize the Chrome browsing experience.', 'A CLI, or command-line interface, is a console that helps users issue commands to a program.', 'Clojure is a dynamic, general-purpose programming language.', 'Automate your code review with style, quality, security, and testâ€‘coverage checks when you need them.', 'Ensure your code meets quality standards and ship with confidence.', 'Compilers are software that translate higher-level programming languages to lower-level languages (e.g. machine code).', 'Automatically build and test your code as you push it upstream, preventing bugs from being deployed to production.', 'The coronavirus disease 2019 (COVID-19) is an infectious disease caused by SARS-CoV-2.', 'C++ is a general purpose and object-oriented programming language.']\n"
     ]
    }
   ],
   "source": [
    "title_desc_tags[:5]\n",
    "new_desc = [desc.text.strip() for desc in title_desc_tags]\n",
    "print(new_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://github.com/topics/3d', 'https://github.com/topics/ajax', 'https://github.com/topics/algorithm', 'https://github.com/topics/amphp', 'https://github.com/topics/android', 'https://github.com/topics/angular', 'https://github.com/topics/ansible', 'https://github.com/topics/api', 'https://github.com/topics/arduino', 'https://github.com/topics/aspnet', 'https://github.com/topics/atom', 'https://github.com/topics/awesome', 'https://github.com/topics/aws', 'https://github.com/topics/azure', 'https://github.com/topics/babel', 'https://github.com/topics/bash', 'https://github.com/topics/bitcoin', 'https://github.com/topics/bootstrap', 'https://github.com/topics/bot', 'https://github.com/topics/c', 'https://github.com/topics/chrome', 'https://github.com/topics/chrome-extension', 'https://github.com/topics/cli', 'https://github.com/topics/clojure', 'https://github.com/topics/code-quality', 'https://github.com/topics/code-review', 'https://github.com/topics/compiler', 'https://github.com/topics/continuous-integration', 'https://github.com/topics/covid-19', 'https://github.com/topics/cpp']\n"
     ]
    }
   ],
   "source": [
    "base_urls = 'https://github.com'\n",
    "all_urls = [base_urls + tags['href'] for tags in link_tag]\n",
    "print(all_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Pandas Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_dict = {\n",
    "    'title': new_headers,\n",
    "    'description': new_desc,\n",
    "    'url': all_urls\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataframe for Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3D</td>\n",
       "      <td>3D refers to the use of three-dimensional grap...</td>\n",
       "      <td>https://github.com/topics/3d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ajax</td>\n",
       "      <td>Ajax is a technique for creating interactive w...</td>\n",
       "      <td>https://github.com/topics/ajax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algorithm</td>\n",
       "      <td>Algorithms are self-contained sequences that c...</td>\n",
       "      <td>https://github.com/topics/algorithm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amp</td>\n",
       "      <td>Amp is a non-blocking concurrency library for ...</td>\n",
       "      <td>https://github.com/topics/amphp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Android</td>\n",
       "      <td>Android is an operating system built by Google...</td>\n",
       "      <td>https://github.com/topics/android</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       title                                        description  \\\n",
       "0         3D  3D refers to the use of three-dimensional grap...   \n",
       "1       Ajax  Ajax is a technique for creating interactive w...   \n",
       "2  Algorithm  Algorithms are self-contained sequences that c...   \n",
       "3        Amp  Amp is a non-blocking concurrency library for ...   \n",
       "4    Android  Android is an operating system built by Google...   \n",
       "\n",
       "                                   url  \n",
       "0         https://github.com/topics/3d  \n",
       "1       https://github.com/topics/ajax  \n",
       "2  https://github.com/topics/algorithm  \n",
       "3      https://github.com/topics/amphp  \n",
       "4    https://github.com/topics/android  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topics = pd.DataFrame(topics_dict)\n",
    "df_topics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a CSV file with the extracted information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topics.to_csv('Github_topics.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://github.com/topics/android'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_all_urls = all_urls[4]\n",
    "response = requests.get(get_all_urls)\n",
    "get_all_urls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://github.com/flutter/flutter'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "h3_loc_tags = 'f3 color-fg-muted text-normal lh-condensed'\n",
    "topics_docs = BeautifulSoup(response.text, 'html.parser')\n",
    "repo_tags = topics_docs.find_all('h3', {'class' : h3_loc_tags})\n",
    "a_tags = repo_tags[0].find_all('a')\n",
    "repo_url = base_urls + a_tags[1]['href']\n",
    "repo_url\n",
    "# # # url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soc = 'tooltipped tooltipped-s btn-sm btn BtnGroup-item color-bg-default'\n",
    "t_ags = topics_docs.find_all('a', {'class' : soc}) \n",
    "\n",
    "# len(social_star_tags)\n",
    "# star_tags = t_ags[0].find_all('span', {'class' : 'Counter js-social-count'})\n",
    "# star_tags[0].text\n",
    "def parse_star(star_str):\n",
    "    star_value = star_str.split()[1]\n",
    "    if star_str[-1] == 'k':\n",
    "        return int(float(star_value[:-1])) * 1000\n",
    "    return int(star_value)\n",
    "parse_star(t_ags[0].text.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('flutter', 'flutter', 'https://github.com/flutter/flutter', 160000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def get_repo_details(h3_tags, star_tag):\n",
    "    \n",
    "    a_tags = h3_tags.find_all('a')\n",
    "    username = a_tags[0].text.strip()\n",
    "    repo_name = a_tags[1].text.strip()\n",
    "    repo_url = base_urls + a_tags[1]['href']\n",
    "    stars = parse_star(star_tag.text.strip())\n",
    "    return username, repo_name, repo_url, stars\n",
    "get_repo_details(repo_tags[0], t_ags[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_repos_dict = {\n",
    "    'username' : [],\n",
    "    'repo_name' : [],\n",
    "    'stars' : [],\n",
    "    'repo_url' : []\n",
    "}\n",
    "\n",
    "for i in range(len(repo_tags)):\n",
    "    repo_info = get_repo_details(repo_tags[i], t_ags[i])\n",
    "    topic_repos_dict['username'].append(repo_info[0])\n",
    "    topic_repos_dict['repo_name'].append(repo_info[1])\n",
    "    topic_repos_dict['stars'].append(repo_info[2])\n",
    "    topic_repos_dict['repo_url'].append(repo_info[3])\n",
    "\n",
    "topic_repos_dict_df = pd.DataFrame(topic_repos_dict)\n",
    "topic_repos_dict_df\n",
    "# repo_info = [get_repo_details(repo_tags[i]) for i in range(len(repo_tags))]\n",
    "# [topic_repos_dict['username']  repo_info[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Functions for Repetition\n",
    "* A function to ``` Get the github Pages ```\n",
    "* A function to ``` Obtain the repository Info```\n",
    "* A function to get the topic repositories from Github then ``` Convert to a Dataframe using Pandas ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def get_topic_page(all_urls):\n",
    "    response = requests.get(all_urls)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception('Failed to load page ()'.format(all_urls))\n",
    "    topics_docs = BeautifulSoup(response.text, 'html.parser')\n",
    "    return topics_docs\n",
    "\n",
    "def get_repo_details(h3_tags, star_tag):\n",
    "    \n",
    "    a_tags = h3_tags.find_all('a')\n",
    "    username = a_tags[0].text.strip()\n",
    "    repo_name = a_tags[1].text.strip()\n",
    "    repo_url = base_urls + a_tags[1]['href']\n",
    "    stars = parse_star(star_tag.text.strip())\n",
    "    return username, repo_name, repo_url, stars\n",
    "\n",
    "def get_topic_repos(topics_docs):\n",
    "    h3_loc_tags = 'f3 color-fg-muted text-normal lh-condensed'\n",
    "    soc = 'tooltipped tooltipped-s btn-sm btn BtnGroup-item color-bg-default'\n",
    "    repo_tags = topics_docs.find_all('h3', {'class' : h3_loc_tags})\n",
    "    t_ags = topics_docs.find_all('a', {'class' : soc}) \n",
    "    \n",
    "    \n",
    "    topic_repos_dict = {\n",
    "    'username' : [],\n",
    "    'repo_name' : [],\n",
    "    'repo_url' : [],\n",
    "    'stars' : []\n",
    "    }\n",
    "\n",
    "    for i in range(len(repo_tags)):\n",
    "        repo_info = get_repo_details(repo_tags[i], t_ags[i])\n",
    "        topic_repos_dict['username'].append(repo_info[0])\n",
    "        topic_repos_dict['repo_name'].append(repo_info[1])\n",
    "        topic_repos_dict['repo_url'].append(repo_info[2])\n",
    "        topic_repos_dict['stars'].append(repo_info[3])\n",
    "    return pd.DataFrame(topic_repos_dict)\n",
    "get_topic_repos(topics_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtain Github Topics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_all_urls = all_urls[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the repository info from topics specified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourth_docs  = get_topic_page(get_all_urls)\n",
    "fourth_repos = get_topic_repos(fourth_docs)\n",
    "fourth_repos\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Functions for different tags\n",
    "* Get the topic titles\n",
    "* Description tags\n",
    "* Topics url\n",
    "* A function call to get the details in a DataFrame, including the ```load more``` functionality using a for loop\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_topics_titles(html_doc):\n",
    "    class_selected = 'f3 lh-condensed mb-0 mt-1 Link--primary'\n",
    "    # Get all title tags\n",
    "    topic_title_tags = html_doc.find_all('p', {'class' : class_selected})\n",
    "    # List comprehension\n",
    "    new_headers = [tags.text for tags in topic_title_tags] \n",
    "    return new_headers\n",
    "\n",
    "def scrape_topics_desc(html_doc):   \n",
    "    selected_class = 'f5 color-fg-muted mb-0 mt-1'\n",
    "    title_desc_tags = html_doc.find_all('p', {'class' : selected_class})\n",
    "    # Get descriptions from the the descriptions tag\n",
    "    new_desc = [desc.text.strip() for desc in title_desc_tags]\n",
    "    return new_desc\n",
    "\n",
    "# def scrape_topics_url(docs):\n",
    "#     base_urls = 'https://github.com'\n",
    "#     all_urls = [base_urls + tags['href'] for tags in link_tag]\n",
    "#     return  all_urls\n",
    "    \n",
    "def get_topics_url(html_doc):\n",
    "    link_tag = html_doc.find_all('a', 'no-underline flex-1 d-flex flex-column')\n",
    "    base_urls = 'https://github.com'\n",
    "    all_urls = [base_urls + tags['href'] for tags in link_tag]\n",
    "    return all_urls\n",
    "def scrape_topics():\n",
    "    topics1_dict = {\n",
    "       'Title': [],\n",
    "        'Description': [],\n",
    "        'URL': []\n",
    "    }\n",
    "    for i in range(1 , 7):\n",
    "        topics_url = f\"https://github.com/topics?page={i}\"  #https://github.com\n",
    "        response = requests.get(topics_url)\n",
    "        if response.status_code != 200:\n",
    "            raise Exception(f\"Failed to load page {topics_url}\")\n",
    "        html_doc= BeautifulSoup(response.text, 'html.parser')\n",
    "        topics1_dict['Title'].extend(scrape_topics_titles(html_doc))\n",
    "        topics1_dict['Description'].extend(scrape_topics_desc(html_doc))\n",
    "        topics1_dict['URL'].extend(get_topics_url(html_doc))\n",
    "\n",
    "    return pd.DataFrame(topics1_dict)\n",
    "scrape_topics()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get all Topics repo\n",
    "- Parse the topic pages into ```get_topic_repos ```, this gets all the topic pages, repos and stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_topic(get_all_urls, topics_name, folder_path):\n",
    "    file_name = os.path.join(folder_path, topics_name + '.csv')\n",
    "    if os.path.exists(file_name):\n",
    "        print(f\"The file name {file_name} already exist. Skipping...\")\n",
    "        return\n",
    "    df_topics = get_topic_repos(get_topic_page(get_all_urls))\n",
    "    df_topics.to_csv(file_name, index = None)\n",
    "    print(f\"CSV file saved: {file_name}\")\n",
    "\n",
    "\n",
    "def scrape_topics_repos(folder_path):\n",
    "    df_topics = scrape_topics()\n",
    "    for index, row in df_topics.iterrows():\n",
    "        print(f\"Scraping top repositories for {row['Title']}\")\n",
    "        scrape_topic(row['URL'], row['Title'], folder_path)\n",
    "\n",
    "folder_path = r'C:\\Users\\Badru\\Videos\\Data_challenges\\data_analysis_project\\github_topics'\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "scrape_topics_repos(folder_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
